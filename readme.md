# バイナリエンコーディングの性能調査

多クラス分類にはone-hotエンコーディングが用いられることが殆どだが、クラス数と同数の出力次元が必要であり、データ量や計算量が膨れ上がってしまう。\
これにはスパース化が効果を発揮するのだが、異なるアプローチとして元のラベル値をバイナリ化する手法が考えられる。

例えば0～9の数字はone-hotなら10次元必要だが、0000～10001の4bitにエンコードしてしまえば4次元に納めることが可能である。

このバイナリ化はクラス数が多ければ多いほど圧縮効果が高まる。\
(32bitなら約43億のラベルを表現可能である。one-hotなら43億次元必要だが、バイナリ化なら32次元で済む。)

本リポジトリでは、MNISTの数字判定を通し、提案するバイナリエンコーディングと従来のone-hotエンコーディングを比較する。

## ファイル内容まとめ

- main.ipynb

  結果の分かりやすさ、実行しやすさを重点に動作をまとめたノートブック

- main.py

  主に実装中に使用するスクリプト\
  整理後回し癖の典型

- models.py

  コアとなる学習モデルを記載するスクリプト\
  学習クラスはここから必要なモデルを取得する

- onehot_trainer.py

  one-hotラベリングを使用して分類を行う学習クラス
  初期設定～train, testのstep関数を用意

- binary_trainer.py

  binaryラベリングを使用して分類を行う学習クラス
  onehotとはデータの前処理や最終層の活性化関数、損失関数、評価関数などが異なる

## 結果の暫定的まとめ

binaryラベリングについて、試行回数が少ないが、MNISTにおいては遜色のない精度を出すことができた。\
今後はデータセットを変えたり(CIFAR-100等)、試行回数を上げ平均を取ること等が必要。