{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-hotラベリングとbinaryラベリングの精度を比較\n",
    "\n",
    "ラベリング手法により精度に違いが表れるかを見る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本的なimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 05:33:54.536734: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベリング手法別の学習クラスを用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 05:33:56.381420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:56.406069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:56.406296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:56.407460: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-19 05:33:56.409153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:56.409279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:56.409372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:57.242995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:57.243683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:57.243699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-08-19 05:33:57.244256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:977] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-19 05:33:57.244354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9325 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from onehot_trainer import OneHotTrainer\n",
    "from binary_trainer import BinaryTrainer\n",
    "\n",
    "oh_trainer = OneHotTrainer()\n",
    "bin_trainer = BinaryTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTの分類精度で比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hotラベリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehot train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 05:34:00.576509: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-08-19 05:34:02.630299: I tensorflow/stream_executor/cuda/cuda_blas.cc:1804] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, \tonehot Loss: 0.22217930853366852, onehot Accuracy: 93.53666687011719, onehot Test Loss: 0.7581745982170105, onehot Test Accuracy: 97.3499984741211\n",
      "Epoch 2, \tonehot Loss: 0.06573574990034103, onehot Accuracy: 98.05833435058594, onehot Test Loss: 0.519260585308075, onehot Test Accuracy: 98.05999755859375\n",
      "Epoch 3, \tonehot Loss: 0.037449318915605545, onehot Accuracy: 98.90666961669922, onehot Test Loss: 0.4673287272453308, onehot Test Accuracy: 98.0999984741211\n",
      "Epoch 4, \tonehot Loss: 0.0242706798017025, onehot Accuracy: 99.29500579833984, onehot Test Loss: 0.36578506231307983, onehot Test Accuracy: 98.43000030517578\n",
      "Epoch 5, \tonehot Loss: 0.015178847126662731, onehot Accuracy: 99.57500457763672, onehot Test Loss: 0.3766848146915436, onehot Test Accuracy: 98.25\n",
      "Epoch 6, \tonehot Loss: 0.009864278137683868, onehot Accuracy: 99.7750015258789, onehot Test Loss: 0.28888896107673645, onehot Test Accuracy: 98.5999984741211\n",
      "Epoch 7, \tonehot Loss: 0.006939064245671034, onehot Accuracy: 99.83000183105469, onehot Test Loss: 0.2966917157173157, onehot Test Accuracy: 98.48999786376953\n",
      "Epoch 8, \tonehot Loss: 0.0035884915851056576, onehot Accuracy: 99.93499755859375, onehot Test Loss: 0.2970309555530548, onehot Test Accuracy: 98.38999938964844\n",
      "Epoch 9, \tonehot Loss: 0.00262510497123003, onehot Accuracy: 99.95999908447266, onehot Test Loss: 0.2613663971424103, onehot Test Accuracy: 98.58999633789062\n",
      "Epoch 10, \tonehot Loss: 0.001732952892780304, onehot Accuracy: 99.97833251953125, onehot Test Loss: 0.26428505778312683, onehot Test Accuracy: 98.54999542236328\n"
     ]
    }
   ],
   "source": [
    "print(\"onehot train\")\n",
    "oh_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binaryラベリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary train\n",
      "Epoch 1, \tbinary Loss: 0.14839805662631989, binary Accuracy: 94.4254150390625, binary Test Loss: 0.6160270571708679, binary Test Accuracy: 97.84500122070312\n",
      "Epoch 2, \tbinary Loss: 0.05254879966378212, binary Accuracy: 98.2366714477539, binary Test Loss: 0.40057870745658875, binary Test Accuracy: 98.4625015258789\n",
      "Epoch 3, \tbinary Loss: 0.034696124494075775, binary Accuracy: 98.8566665649414, binary Test Loss: 0.3161502480506897, binary Test Accuracy: 98.74250030517578\n",
      "Epoch 4, \tbinary Loss: 0.02445315383374691, binary Accuracy: 99.22416687011719, binary Test Loss: 0.2669053375720978, binary Test Accuracy: 98.8324966430664\n",
      "Epoch 5, \tbinary Loss: 0.018198108300566673, binary Accuracy: 99.41124725341797, binary Test Loss: 0.23325739800930023, binary Test Accuracy: 98.9124984741211\n",
      "Epoch 6, \tbinary Loss: 0.013227324932813644, binary Accuracy: 99.600830078125, binary Test Loss: 0.22408021986484528, binary Test Accuracy: 98.98249816894531\n",
      "Epoch 7, \tbinary Loss: 0.009780319407582283, binary Accuracy: 99.71916961669922, binary Test Loss: 0.19790765643119812, binary Test Accuracy: 99.0250015258789\n",
      "Epoch 8, \tbinary Loss: 0.00679353391751647, binary Accuracy: 99.82167053222656, binary Test Loss: 0.18420526385307312, binary Test Accuracy: 99.04249572753906\n",
      "Epoch 9, \tbinary Loss: 0.0051550548523664474, binary Accuracy: 99.87042236328125, binary Test Loss: 0.1809278428554535, binary Test Accuracy: 98.99500274658203\n",
      "Epoch 10, \tbinary Loss: 0.0036686905659735203, binary Accuracy: 99.91458129882812, binary Test Loss: 0.16568705439567566, binary Test Accuracy: 99.09500122070312\n"
     ]
    }
   ],
   "source": [
    "print(\"binary train\")\n",
    "bin_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "精度の差は大きくなかった\\\n",
    "どちらかといえばバイナリの方が良い？\n",
    "\n",
    "出力次元が気になるならバイナリ化するのは悪い手法ではない様子"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
